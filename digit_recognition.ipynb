{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "digit-recognition.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DanDas3/reconhecimento-digitos/blob/master/digit_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQLTRyjBBgQB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#coding: utf-8\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import imutils\n",
        "import os\n",
        "import keras #Rede Neural\n",
        "from keras.layers import MaxPooling2D, Flatten, Dense, Dropout\n",
        "from matplotlib import pyplot as plt\n",
        "from getpass import getpass\n",
        "from os import listdir\n",
        "from os.path import isfile, join"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RoBIe9lDCCN4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "root = \"reconhecimento-digitos\"\n",
        "data_root = \"data\"\n",
        "out_path_root = \"output\"\n",
        "digits_trains = \"cvl-single-digits-train-validation/train\"\n",
        "digits_eval = \"cvl-single-digits-train-validation/valid\"\n",
        "digits_valid = \"cvl-single-digits-completeDatabase/cvl-single-digits/valid/\"\n",
        "string_trains = \"cvl-strings-train/train\"\n",
        "string_eval = \"cvl-strings-eval/cvl-strings-eval\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOkJZGaiCJc8",
        "colab_type": "code",
        "outputId": "50b89d0d-fc95-4692-c4c5-910bf66f5d8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "if os.path.exists(root) == False:\n",
        "  !git clone https://github.com/DanDas3/reconhecimento-digitos.git"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'reconhecimento-digitos'...\n",
            "remote: Enumerating objects: 55, done.\u001b[K\n",
            "remote: Counting objects: 100% (55/55), done.\u001b[K\n",
            "remote: Compressing objects: 100% (55/55), done.\u001b[K\n",
            "remote: Total 79500 (delta 21), reused 1 (delta 0), pack-reused 79445\u001b[K\n",
            "Receiving objects: 100% (79500/79500), 187.79 MiB | 14.28 MiB/s, done.\n",
            "Resolving deltas: 100% (25/25), done.\n",
            "Checking out files: 100% (93529/93529), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epvhmoDUCVyf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Funções\n",
        "\n",
        "#def convertBin(img):\n",
        "#  max_value = 255\n",
        "#  neighborhood_size=99\n",
        "#  subtract_from_mean = 10\n",
        "#  return cv.adaptiveThreshold(img, max_value, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY, neighborhood_size, subtract_from_mean)\n",
        "  #return cv.threshold(img, 200, 255, cv.THRESH_BINARY)\n",
        "\n",
        "def GaussianFilter(img):\n",
        "  return cv.GaussianBlur(img, (5, 5), 0)\n",
        "\n",
        "def morphologyFilter(img):\n",
        "  img = cv.threshold(img, 225, 255, cv.THRESH_BINARY_INV)[1]\n",
        "  img = cv.erode(img, cv.getStructuringElement(cv.MORPH_ELLIPSE, (3, 1)))\n",
        "  img = cv.dilate(img, cv.getStructuringElement(cv.MORPH_ELLIPSE, (1, 3)))\n",
        "  return img\n",
        "def ordenaContornos(cnts):\n",
        "  for i in range(len(cnts)):\n",
        "      for j in range(i+1,len(cnts)):\n",
        "          x_i = cv.boundingRect(cnts[i])[0]\n",
        "          x_j = cv.boundingRect(cnts[j])[0]\n",
        "\n",
        "          if(x_j < x_i):\n",
        "              aux = cnts[j]\n",
        "              cnts[j] = cnts[i]\n",
        "              cnts[i] = aux\n",
        "  return cnts  \n",
        "\n",
        "def extrairRecortes(img, cnts):\n",
        "  recorte = []\n",
        "  copy = img.copy()\n",
        "  for c in cnts:\n",
        "    # dados do contorno\n",
        "    (x, y, w, h) = cv.boundingRect(c)\n",
        "    if w >= 5 and h >= 17:\n",
        "      if (w >= 50):  # Divide a região em duas\n",
        "        copy = cv.rectangle(copy, (x, y), (x + (w // 2), y + h), (0, 255, 0), 2)\n",
        "        i = copy[y:y + h, x:x + (w // 2)]\n",
        "        i = cv.resize(i, (32, 32))      \n",
        "        recorte.append(i)\n",
        "\n",
        "        i = copy[y:y + h, x + ((w // 2) + 1):x + w]\n",
        "        copy = cv.rectangle(copy, (x, y), ((x + (w // 2) + 1) + (w // 2), y + h), (0, 255, 0), 2)\n",
        "        i = cv.resize(i, (32, 32))\n",
        "        # recorte.append(img[index_img][y:y + h, x + ((w // 2) + 1):x + w])\n",
        "        recorte.append(i)\n",
        "      else:\n",
        "        copy = cv.rectangle(copy, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "        i = copy[y:y + h, x:x + w]\n",
        "        i = cv.resize(i, (32, 32))\n",
        "        # recorte.append(img[index_img][y:y + h, x:x + w])\n",
        "        recorte.append(i)\n",
        "  return recorte, copy\n",
        "\n",
        "def encontraContornos(img):\n",
        "  cnts = cv.findContours(img.copy(), cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
        "  cnts = imutils.grab_contours(cnts)\n",
        "  cnts = ordenaContornos(cnts)\n",
        "  return cnts\n",
        "\n",
        "def marcarSegmentos(img, positions):\n",
        "  for position in positions:\n",
        "    cv.rectangle(img, position[0],position[1],(0,0,0),thickness=2)\n",
        "  return img\n",
        "\n",
        "def carregaDigitTrain():\n",
        "  path = root + \"/\" + data_root + \"/\" + digits_trains + \"/\"\n",
        "  images = [f for f in listdir(path) if isfile(join(path, f))]\n",
        "  data = np.ndarray((len(images), 32, 32, 3))\n",
        "  tags = np.ndarray((len(images), 1))\n",
        "  for i in range(len(images)):\n",
        "    img = cv.imread(path + images[i])\n",
        "    img = cv.resize(img,(32,32))\n",
        "    tags[i] = int(images[i][:1])\n",
        "    data[i] = img\n",
        "  return data, tags\n",
        "\n",
        "def carregaDigitEval():\n",
        "  path = root + \"/\" + data_root + \"/\" + digits_eval + \"/\"\n",
        "  images = [f for f in listdir(path) if isfile(join(path, f))]\n",
        "  data = np.ndarray((len(images), 32, 32, 3))\n",
        "  tags = np.ndarray((len(images), 1))\n",
        "  for i in range(len(images)):\n",
        "    img = cv.imread(path + images[i])\n",
        "    img = cv.resize(img,(32,32))\n",
        "    tags[i] = int(images[i][:1])\n",
        "    data[i] = img\n",
        "  \n",
        "  return data, tags\n",
        "\n",
        "def carregaDigitValid():\n",
        "  path = root + \"/\" + data_root + \"/\" + digits_valid + \"/\"\n",
        "  images = [f for f in listdir(path) if isfile(join(path, f))]\n",
        "  data = np.ndarray((len(images), 32, 32, 3))\n",
        "  tags = np.ndarray((len(images), 1))\n",
        "  for i in range(len(images)):\n",
        "    img = cv.imread(path + images[i])\n",
        "    img = cv.resize(img,(32,32))\n",
        "    tags[i] = int(images[i][:1])\n",
        "    data[i] = img\n",
        "  return data, tags\n",
        "\n",
        "def carregaStringsValid():\n",
        "  path = root + \"/\" + data_root + \"/\" + string_eval + \"/\"\n",
        "  images = [f for f in listdir(path) if isfile(join(path, f))]\n",
        "  #data = np.ndarray((len(images), 365, 32, 3))\n",
        "  #tags = np.ndarray((len(images), 1))\n",
        "  data = []\n",
        "  digits = []\n",
        "  for i in range(len(images)):\n",
        "    img = cv.imread(path + images[i],0)\n",
        "    #img = cv.resize(img,(365,89))    \n",
        "    tag_num = images[i].split(\"-\",1)[0]\n",
        "    for j in range(len(tag_num)):\n",
        "      digits.append(tag_num[j])\n",
        "    data.append((img, digits))  \n",
        "    #tags[i] = int(tag_num)\n",
        "    #data[i] = img\n",
        "  \n",
        "  return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNqD7N-X82zx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_train, tag_train = carregaDigitTrain()\n",
        "\n",
        "data_eval, tag_eval = carregaDigitEval()\n",
        "\n",
        "data_valid, tag_valid = carregaDigitValid()\n",
        "\n",
        "string_digits=carregaStringsValid()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aI7Eg5sV92mJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "outputId": "d759bfad-9892-45f2-e3eb-1065993ac2c9"
      },
      "source": [
        "img = string_digits[0][0]\n",
        "\n",
        "blur = GaussianFilter(img)\n",
        "\n",
        "binImg = morphologyFilter(blur)\n",
        "\n",
        "cnts = encontraContornos(binImg)\n",
        "\n",
        "cnts = ordenaContornos(cnts)\n",
        "\n",
        "marcado, recortes = marcarSegmentos(img, cnts)\n",
        "\n",
        "#recortes = extrairRecortes(img, cnts)\n",
        "#print(len(recortes))\n",
        "\n",
        "fig,axes = plt.subplots(5, 1, figsize=(15, 5))\n",
        "ax = axes.ravel()\n",
        "\n",
        "ax[0].imshow(cv.cvtColor(img, cv.COLOR_GRAY2BGR))\n",
        "ax[0].set_title(\"Imagem Original\")\n",
        "ax[0].set_axis_off()\n",
        "\n",
        "ax[1].imshow(cv.cvtColor(blur, cv.COLOR_GRAY2BGR))\n",
        "ax[1].set_title(\"Filtro Gaussiano\")\n",
        "ax[1].set_axis_off()\n",
        "\n",
        "ax[2].imshow(binImg)\n",
        "ax[2].set_title(\"Imagem Binarizada\")\n",
        "ax[2].set_axis_off()\n",
        "\n",
        "ax[3].imshow(cv.cvtColor(marcado, cv.COLOR_BGR2RGB))\n",
        "ax[3].set_title(\"Segmentos Marcados\")\n",
        "ax[3].set_axis_off()\n",
        "\n",
        "#ax[4].imshow(cv.cvtColor(recortes[0], cv.COLOR_BGR2RGB))\n",
        "ax[4].set_title(\"Recorte\")\n",
        "ax[4].set_axis_off()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SystemError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-16c0c532cef9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mcnts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mordenaContornos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mmarcado\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecortes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmarcarSegmentos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#recortes = extrairRecortes(img, cnts)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-45-98f4147fc7a2>\u001b[0m in \u001b[0;36mmarcarSegmentos\u001b[0;34m(img, positions)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmarcarSegmentos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mposition\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpositions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrectangle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mposition\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mthickness\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSystemError\u001b[0m: new style getargs format but argument is not a tuple"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xq8z6nFcSgCQ",
        "colab_type": "text"
      },
      "source": [
        "# Teste Rede Neural"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuhodTnHCqib",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Rede Neural\n",
        "from keras.datasets import imdb\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "# Set random seed\n",
        "np.random.seed(0)\n",
        "\n",
        "# Set the number of features we want\n",
        "number_of_features = 1000\n",
        "\n",
        "# Load data and target vector from movie review data\n",
        "(data_train, target_train), (data_test, target_test) = imdb.load_data(\n",
        "num_words=number_of_features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GP_o-HRMHBy2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Divide em treinamento, teste e validação\n",
        "(data_train, data_valid) = data_train[number_of_features//2:], data_train[:number_of_features//2]\n",
        "(target_train, target_valid) = target_train[number_of_features//2:], target_train[:number_of_features//2]\n",
        "# Convert movie review data to one-hot encoded feature matrix\n",
        "tokenizer = Tokenizer(num_words=number_of_features//2)\n",
        "features_train = tokenizer.sequences_to_matrix(data_train, mode=\"binary\")\n",
        "features_valid = tokenizer.sequences_to_matrix(data_valid, mode=\"binary\")\n",
        "\n",
        "data_test = data_test[:500]\n",
        "target_test = target_test[:500]\n",
        "tokenizer = Tokenizer(num_words=number_of_features//2)\n",
        "features_test = tokenizer.sequences_to_matrix(data_test, mode=\"binary\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5xT1tFdHJFd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Start neural network\n",
        "network = models.Sequential()\n",
        "\n",
        "# Add fully connected layer with a ReLU activation function\n",
        "network.add(layers.Dense(units=16, activation=\"relu\", input_shape=(number_of_features//2,)))\n",
        "\n",
        "# Add fully connected layer with a ReLU activation function\n",
        "network.add(layers.Dense(units=16, activation=\"relu\"))\n",
        "\n",
        "# Add fully connected layer with a sigmoid activation function\n",
        "network.add(layers.Dense(units=1, activation=\"sigmoid\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwHBb9n3HR91",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile neural network\n",
        "network.compile(loss=\"binary_crossentropy\", # Cross-entropy\n",
        "optimizer=\"rmsprop\", # Root Mean Square Propagation\n",
        "metrics=[\"accuracy\"]) # Accuracy performance metric"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2JY5blnHYpd",
        "colab_type": "code",
        "outputId": "9915f266-1406-42db-97e1-2e7b20602142",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Train neural network\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint   \n",
        "\n",
        "# Salva o melhor resultado\n",
        "checkpointer = ModelCheckpoint(filepath='model.weights.best.hdf5', verbose=1, save_best_only=True)\n",
        "\n",
        "history = network.fit(features_train, # Features\n",
        "target_train, # Target vector\n",
        "epochs=20, # Number of epochs\n",
        "verbose=2, # Print description after each epoch\n",
        "batch_size=10, # Number of observations per batch\n",
        "validation_data=(features_valid, target_valid), # Validation data\n",
        "callbacks=[checkpointer],\n",
        "shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 24500 samples, validate on 500 samples\n",
            "Epoch 1/20\n",
            " - 7s - loss: 0.3699 - acc: 0.8433 - val_loss: 0.3579 - val_acc: 0.8420\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.35786, saving model to model.weights.best.hdf5\n",
            "Epoch 2/20\n",
            " - 7s - loss: 0.3627 - acc: 0.8460 - val_loss: 0.3538 - val_acc: 0.8320\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.35786 to 0.35381, saving model to model.weights.best.hdf5\n",
            "Epoch 3/20\n",
            " - 8s - loss: 0.3547 - acc: 0.8524 - val_loss: 0.3785 - val_acc: 0.8400\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.35381\n",
            "Epoch 4/20\n",
            " - 8s - loss: 0.3470 - acc: 0.8577 - val_loss: 0.3731 - val_acc: 0.8340\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.35381\n",
            "Epoch 5/20\n",
            " - 8s - loss: 0.3397 - acc: 0.8637 - val_loss: 0.4094 - val_acc: 0.8420\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.35381\n",
            "Epoch 6/20\n",
            " - 8s - loss: 0.3330 - acc: 0.8682 - val_loss: 0.3988 - val_acc: 0.8240\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.35381\n",
            "Epoch 7/20\n",
            " - 7s - loss: 0.3242 - acc: 0.8719 - val_loss: 0.4243 - val_acc: 0.8340\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.35381\n",
            "Epoch 8/20\n",
            " - 7s - loss: 0.3173 - acc: 0.8771 - val_loss: 0.4455 - val_acc: 0.8320\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.35381\n",
            "Epoch 9/20\n",
            " - 7s - loss: 0.3115 - acc: 0.8808 - val_loss: 0.4528 - val_acc: 0.8360\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.35381\n",
            "Epoch 10/20\n",
            " - 8s - loss: 0.3059 - acc: 0.8850 - val_loss: 0.4449 - val_acc: 0.8300\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.35381\n",
            "Epoch 11/20\n",
            " - 7s - loss: 0.3032 - acc: 0.8856 - val_loss: 0.4327 - val_acc: 0.8360\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.35381\n",
            "Epoch 12/20\n",
            " - 8s - loss: 0.2967 - acc: 0.8880 - val_loss: 0.4369 - val_acc: 0.8480\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.35381\n",
            "Epoch 13/20\n",
            " - 8s - loss: 0.2943 - acc: 0.8911 - val_loss: 0.4213 - val_acc: 0.8440\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.35381\n",
            "Epoch 14/20\n",
            " - 7s - loss: 0.2908 - acc: 0.8942 - val_loss: 0.4378 - val_acc: 0.8240\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.35381\n",
            "Epoch 15/20\n",
            " - 7s - loss: 0.2862 - acc: 0.8945 - val_loss: 0.4419 - val_acc: 0.8280\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.35381\n",
            "Epoch 16/20\n",
            " - 7s - loss: 0.2822 - acc: 0.8966 - val_loss: 0.4872 - val_acc: 0.8340\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.35381\n",
            "Epoch 17/20\n",
            " - 8s - loss: 0.2766 - acc: 0.8995 - val_loss: 0.4703 - val_acc: 0.8320\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.35381\n",
            "Epoch 18/20\n",
            " - 7s - loss: 0.2749 - acc: 0.9011 - val_loss: 0.4719 - val_acc: 0.8380\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.35381\n",
            "Epoch 19/20\n",
            " - 8s - loss: 0.2686 - acc: 0.9040 - val_loss: 0.5700 - val_acc: 0.8280\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.35381\n",
            "Epoch 20/20\n",
            " - 8s - loss: 0.2658 - acc: 0.9050 - val_loss: 0.5549 - val_acc: 0.8260\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.35381\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBZYLctNMKxd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Carrega os pesos com melho precisão na validação\n",
        "network.load_weights('model.weights.best.hdf5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuOrb4bpOb2K",
        "colab_type": "code",
        "outputId": "5b237881-5980-4e60-a1a8-2dbe96addeb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "print(features_test.shape)\n",
        "print(features_test[0].shape)\n",
        "print(features_test[0:1].shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(500, 500)\n",
            "(500,)\n",
            "(1, 500)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3y9hqnYM4OD",
        "colab_type": "code",
        "outputId": "ca0e19d6-074a-470d-c4e9-a1ab27e3e137",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Avaliaçãão do treinamento\n",
        "score = network.evaluate(features_test, target_test, verbose=0)\n",
        "print(\"\\n\",\"Resultado:\", score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Resultado: 0.8400000009536743\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxClsW57S_Hd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_hat = network.predict(features_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JP-5a5EaTLIw",
        "colab_type": "code",
        "outputId": "27fcf2bf-25a8-4052-a9c6-ce2e83012118",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        }
      },
      "source": [
        "print(type(data_test[0]))\n",
        "print(type(target_test[0]))\n",
        "print(target_test[2])\n",
        "for i, idx in enumerate(np.random.choice(features_test.shape[0], size=32, replace=False)):\n",
        "  pred_idx = np.argmax(y_hat[idx])\n",
        "  true_idx = np.argmax(data_test[idx])\n",
        "\n",
        "  print(data_test[true_idx] == data_test[pred_idx] )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'list'>\n",
            "<class 'numpy.int64'>\n",
            "1\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}